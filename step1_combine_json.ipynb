{"cells": [{"cell_type": "markdown", "metadata": {"id": "qU9YNcEd4vCR"}, "source": ["Since json data is only available for 2019-2022 at the current moment, 2017-2018 are currently omitted."]}, {"cell_type": "markdown", "metadata": {"id": "5QewZFH5gG5a"}, "source": ["# News Data Processing Script\n", "\n", "This script processes news data stored in JSON format and converts it into a CSV file.\n", "\n", "## Script Workflow\n", "\n", "The script performs the following steps:\n", "\n", "1. **Mounts Google Drive:** This connects to the user's Google Drive to access the data files using the `google.colab.drive` module.\n", "2. **Installs necessary libraries:** This installs the `dropbox` library using `pip` for interacting with Dropbox. It also imports `json`, `csv`, `os`, `glob`, and `tqdm` for data processing and file handling.\n", "3. **Defines file paths:** This sets the paths to the raw news data folder, project folder, and the dataset folder within Google Drive.\n", "4. **Sets Dropbox access token:** This sets the access token for authenticating with Dropbox.\n", "5. **Defines years to process:** This specifies the years of data to be processed.\n", "6. **Processes data from Google Drive (if applicable):**\n", "    - If the data is already in Google Drive, it iterates through the specified years.\n", "    - It reads JSON files from the raw news data folder for each year.\n", "    - It extracts the file name, ID, and content from each JSON record.\n", "    - It writes the extracted data to a CSV file in the dataset folder.\n", "7. **Processes data from Dropbox (if applicable):**\n", "    - If the data is in Dropbox, it initializes the Dropbox client using the access token.\n", "    - It retrieves a list of files from the specified Dropbox folder path.\n", "    - It iterates through the files, downloads them, and reads the JSON data.\n", "    - It extracts the file name, ID, and content from each JSON record.\n", "    - It writes the extracted data to a CSV file in the dataset folder.\n", "\n", "## Input\n", "\n", "- JSON files containing news data for each year, stored either in Google Drive or Dropbox.\n", "- File paths specified in the `json_dir`, `project_folder`, and `dataset_folder` variables.\n", "- Dropbox access token.\n", "\n", "## Output\n", "\n", "- A CSV file named `combined_data_{year}.csv` for each year, containing the extracted data from the JSON files. The CSV file includes columns for file name, ID, and content.\n", "\n", "## Dependencies\n", "\n", "- `dropbox`\n", "- `json`\n", "- `csv`\n", "- `os`\n", "- `glob`\n", "- `tqdm`\n", "- `google.colab` (for Google Colab environment)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "iItbB0lvljQ1", "outputId": "4ba7551a-ed99-4b54-e899-ff6bfc5a9841"}, "outputs": [], "source": ["from google.colab import drive\n", "drive.mount('/content/drive')"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ed_GR3HflQv_", "outputId": "e8db905e-5355-4ce7-b789-553bbeba4439"}, "outputs": [], "source": ["!pip install dropbox\n", "\n", "import json\n", "import csv\n", "import os\n", "import glob\n", "from tqdm import tqdm\n", "import dropbox"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "kDR_aJI-v5AD"}, "outputs": [], "source": ["# Directory containing your JSON files\n", "json_dir = '/content/drive/MyDrive/2024SUDSProject/rawNewsData/newsdata_'\n", "project_folder = \"/content/drive/MyDrive/2024SUDSProject/\"\n", "dataset_folder = \"/content/drive/MyDrive/2024SUDSProject/processedNewsData/\"\n", "\n", "def create_dropbox_folder_path(year):\n", "    return f'/CCAMO/Data/Unconverted/nela-gt-{year}/newsdata/'"]}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "i-59_b2gwAmj"}, "outputs": [], "source": ["# define your years here. best to do each year one by one to prevent the google colab notebook from timing out.\n", "\n", "years = ['2022']\n", "\n", "dropbox_access_token = 'YOUR_TOKEN_HERE'"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "mT_88yTblQwN", "outputId": "19fba90c-505a-4161-dbbf-7a016f272faa"}, "outputs": [], "source": ["# If the dataset is already in the Google Drive\n", "\n", "for year in years:\n", "    with open(dataset_folder+f'combined_data_{year}.csv', 'w', newline='', encoding='utf-8') as file:\n", "        writer = csv.writer(file)\n", "        writer.writerow(['file_name', 'id', 'content'])  # Writing the header\n", "\n", "        # Get a list of all JSON files\n", "\n", "        json_files = glob.glob(os.path.join(json_dir+year, '*.json'))\n", "        # Iterate over all JSON files in the directory with a progress bar\n", "        for json_file in tqdm(json_files, desc=\"Processing JSON files\", miniters=1):\n", "            # Read the JSON file\n", "            with open(json_file, 'r', encoding='utf-8') as file:\n", "                data = json.load(file)\n", "\n", "            file_name = os.path.splitext(os.path.basename(json_file))[0]\n", "\n", "            for record in data:\n", "                id_value = record.get('id', '')\n", "                content_value = record.get('content', '')\n", "                writer.writerow([file_name, id_value, content_value])\n", "\n", "print(\"Conversion complete.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "qid9yYUVWL0T", "outputId": "bdafa11e-8f1a-436d-c8ac-c7ffc409420e"}, "outputs": [], "source": ["# If the dataset is in Dropbox (short term solution, switch to streaming rows directly to csv instead of writing to memory)\n", "\n", "def import_from_dropbox(year, dropbox_folder_path):\n", "    # Initialize Dropbox client\n", "    dbx = dropbox.Dropbox(dropbox_access_token)\n", "\n", "    result = dbx.files_list_folder(dropbox_folder_path)\n", "\n", "    files = result.entries\n", "\n", "    # Iterate over rest of files in the folder\n", "    while result.has_more:\n", "        result = dbx.files_list_folder_continue(result.cursor)\n", "        files.extend(result.entries)\n", "\n", "    total_data = []\n", "\n", "    for file in tqdm(files, desc=\"Reading JSON files from Dropbox\", miniters=1):\n", "        _, file_response = dbx.files_download(file.path_lower)\n", "\n", "        # Read JSON data\n", "        json_data = file_response.content.decode('utf-8')\n", "        json_data = json.loads(json_data)\n", "        for record in json_data:\n", "            id_value = record.get('id', '')\n", "            content_value = record.get('content', '')\n", "            total_data.append([id_value.split('--')[0], id_value, content_value])\n", "\n", "\n", "    keys = ['file_name', 'id', 'content']  # Writing the header\n", "\n", "    # Write to CSV file\n", "    with open(dataset_folder+f'combined_data_{year}.csv', 'w', newline='') as csv_file:\n", "        writer = csv.writer(csv_file)\n", "        writer.writerow(keys)\n", "        writer.writerows(total_data)\n", "\n", "    # print(f'Conversion Complete')\n", "\n", "import_from_dropbox('2020', create_dropbox_folder_path('2020'))\n"]}], "metadata": {"colab": {"provenance": [{"file_id": "1aDMgo7IDqtuDxPkQizzX11pmAZhmG_Uo", "timestamp": 1716762416552}]}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.7"}}, "nbformat": 4, "nbformat_minor": 0}