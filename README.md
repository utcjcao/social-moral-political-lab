# SCORE BREAKDOWN

## Guided LDA Breakdown

This breaks down how the algorithm works, the output, and some potential issues and next action steps.

Note: this repository only contains the code written for the project. It does not include any of the required data, models, labels, or other assets needed to run the notebooks.

### Step 1: Input

- **Documents:** collection of text documents. Each document transformed into a Bag of Words (BoW).
  - Doesn’t preserve sentence structure, or words like “and”, “but”, “this”.
- **Seed words:** a set of words you want to associate with specific topics.
- **Priori:** the seed words translated into a topic–word distribution to be seeded into the model.
- **Moral foundations dictionary:** a list of words, each with a corresponding moral foundations score for each moral foundations category.
  - Each category is scored from 0 to 1, but categories do not always add up to 1.

### Step 2: Model initializes

Start with random distributions:

- **Topic–Word Distribution:** each topic is randomly initialized with a distribution over words.
- **Document–Topic Distribution:** each document is randomly assigned a distribution over topics.

### Step 3: Add Guidance

- Add priori: model adjusts the topic–word distributions so that these seed words are more likely to be assigned to the priori.

### Step 4: Algorithm

For each word in a document, the algorithm calculates:

- **p(topic t | document d):** given the document words, what's the probability that the word belongs to a topic?  
  Calculated by:

  - finding the proportion of words in the document that are assigned to that topic.
  - if there are a lot of words in the document that belong to that topic, it's more likely that the word is related to that topic.

- **p(word w | topic t):** probability that a word belongs to a topic.  
  Calculated by:
  - finding the proportion of times the word is assigned to a topic across all documents, reflecting how strongly the word is associated with the topic.

Readjusts the probability a word is associated with a topic with:

- **p(word w with topic t) = p(topic t | document d) \* p(word w | topic t)**

Intuition:

- If a word is in a document that has a lot of words related with topic “sports”, but its overall association with the word “sport” from other documents isn’t that high, the probability will go down.
- Same applies if the word is in a document that doesn’t have a lot of words related with “sport”, but its overall association with the word “sport” is high.
- But if a word is in a document that is related to “sport”, and its overall association with the word “sport” across all other documents is high, then its probability will increase.

This repeats until the topic distributions stabilize.

### Step 5: Output

Output is returned as follows and all are built on each other sequentially:

- **Model:** the trained LDA model for a particular year
- **Topic_words_and_contributions:** using the topics generated by the model, `Topic_words_and_contributions` is a 2D list, where:

  - each list represents one topic
  - each list contains the top 100 words that contribute to said topic
  - words are bundled as tuples: `(word, contribution)`

- **Word_scores_df:** using `topic_words_and_contributions` and the moral foundations dictionary, `word_scores_df` is a pandas dataframe (imagine a csv file), containing the following columns:

  - Topic
  - Word
  - Contribution

  For each word in `topic_words_and_contributions`, we either:

  - If the word is in the moral foundations dictionary, we use the preexisting moral foundation score as the data entry.
  - If the word isn’t in the moral foundations dictionary:
    - use a word2vec model that finds the top 10 most similar words, and uses the average between all of them
    - if no words are found, use 0

- **topic_scores:** using `word_scores_df`, we calculate `topic_scores` by:

  - For each topic, iterate through all the words that contribute
  - Sum the product of:
    - the word contribution to the topic, and
    - the moral foundation category score of the word (from `word_scores_df`)

  This gives a weighted score for each word in a topic.

  - So for each topic, this returns a moral foundation score for all categories.

- **doc_topic_dist_df:** using the BoW, we calculate the topic distribution per document by creating a pandas dataframe with the following columns:

  - Topics 0–9:
    - represents the individual contribution for each topic in the document
    - topics will sum up to 1
  - Filename
  - Topic Distribution:
    - contains the largest individual topic distribution  
      (larger implies a distinct topic is present, while smaller implies that topics are generalized)
  - Year

- **Doc_mf_scores_df:** using `doc_topic_dist_df` and `topic_scores`, we calculate the weighted moral foundation scores for each document:

  For each document:

  - retrieve the topic distribution for the document
  - initialize a dictionary `doc_mf_scores` to store the moral foundation scores for the current document
  - iterate through each moral foundation category
  - for each moral foundation category:
    - calculate a weighted score by multiplying:
      - the topic probabilities (from `doc_topic_dist_df`), with
      - the corresponding topic-level moral foundation scores (from `topic_scores`)
    - sum these weighted scores to obtain the overall moral foundation score for the document for that category

---

## Reasons we might be seeing non-zero / very stable values

- **Overfitting:**  
  if we run the model too long, then the topic stabilization continues beyond what it's supposed to be and is flatter than normal
- **Alpha value too high:**  
  alpha controls how much the model spreads topics across documents. If alpha is too high, we might be blocking it from appropriately distributing topics.
- **Beta value too high:**  
  beta controls how much the model spreads words across topics. If beta is too high, each word will have similar topic probabilities, so topics are less distinct.
- **Not enough / too much topics:**
  - not enough topics may make each topic very general
  - too many topics may overfit the data
- **Low quality data:**
  - if words are too closely related / not enough variety, topics may not be distinct
  - if documents are too short, not enough data to assign topics
  - if document word content contains mainly common/weak words, there is a lack of distinct boundaries and so topics might be general

## Action steps

- **Consider not using EMFD word weighting and just use topic distributions:**

  - previously: compute topic-level moral foundation scores → then compute doc-level scores by weighting by topic distribution
  - instead: use the topic distribution scores directly
  - downside: removes nuances of the moral foundation dictionary scores
  - potential workaround: when we create our `eta`, use moral foundation dictionary scores to weigh some words more importantly than others, preserving nuance without requiring the weighting step

- **To fix overfitting / alpha / beta:**

  - experiment with different parameters
  - needs to be done over a long time frame because training each model and judging output quality takes a long time

- **Not enough / too much topics:**

  - can’t be fixed because we need these 10 topics

- **Low quality data:**
  - **Lack of word variety:** adjust priori such that words that are highly associated with each topic are removed
    - risk: may erase important details from priori
  - **Documents too short:** consider removing articles with little to no words
    - risk: may make news outlet distribution of articles uneven
  - **Too many common words:** should already be dealt with, as documents were already stemmed and lemmatized before being processed

---

# Threat Breakdown

### Step 1: Input Data

- **Documents:** collection of text documents. Documents have been lemmatized.
- **Threat corpus:** collection of words that are threat-related.

### Step 2: Algorithm

For each article:

- count the occurrences of each word in the article's content
- `total_words`: total number of words in the article
- `target_list_occurences`: counts the occurrences of words from `target_list` (threat words) in the article

Calculate proportion:

- `proportion`: proportion of threat words to total words in the article
  - `proportion = target_list_occurences / total_words`
  - if the article has no words, the proportion is set to 0

Creates two new columns in the DataFrame:

- `threat_proportional_score`: stores the calculated proportions
- `total_word_count`: stores the total word counts

### Step 3: Output

Returns a csv with the following columns:

- `Outlet`: news outlet name
- `Label`: political leaning
- `Id`: article name and ID
- `Threat_proportional_score`: number of threat words divided by total word count
- `Total_word_count`: total word count of an article
- `Year`

### Potential Issues

- after cleaning, some articles are 1–2 words, so the proportional threat score may be 100%

---

# Honor Breakdown

### Step 1: Input Data

- **Documents:** collection of text documents. Documents have been lemmatized.
- **Honor dictionary:** collection of honor categories that contain words
  - Source: https://www.michelegelfand.com/honor-dictionary

### Step 2: Algorithm

For each article:

- `counted_words`: count the frequency of each word in an article
- `total_word_count`: stores the total number of words in the article
- compute word count proportions by dividing each word's count by total word count to ensure honor scores are comparable across articles of different lengths
- initialize a dictionary `category_counts` to store the counts for each honor category, starting at 0
- iterate through the words and their normalized counts in `counted_words`
- if a word is found in the `honor_words` dictionary (loaded from the honor dictionary file), it means the word is related to honor
- for each honor category associated with the word (obtained from `honor_words`), increment the count for that category by the word's normalized frequency:
  - `category_counts[category] += count`

### Step 3: Output

Returns a csv with the following columns:

- `Outlet`: news outlet name
- `Label`: pol
- `Id`: article name and ID
- all honor dictionary categories (e.g., `Honor Gain`, ...)
- `Year`

### Potential Issues

- after cleaning, some articles are 1–2 words, so we may need to remove from dataset

---

# DATA

The data included is:

- **Combined_honor_score.csv**
  - contains calculated honor data from 2019–2022
- **Mf_doc_mf_scores.csv**
  - contains aggregated moral foundation scores for each document from 2019–2022
  - done by finding word topic distributions and calculating overall scores per document
- **Mf_combined_topic_dist.csv**
  - contains document topic distributions from 2019–2022
- **Combined_threat_score.csv**
  - contains calculated threat data from 2019–2022

# CODE

The code included is:

- **Step1_combine_json.ipynb**
  - combines the unprocessed json data
- **Step2_lemmatize_data.ipynb**
  - lemmatizes raw data
- **Step2_stem_data.ipynb**
  - stems raw data
- **Step3_calculate_honor.ipynb**
  - calculates honor data
- **Step3_calculate_threat.ipynb**
  - calculates threat data
- **Step3_load_vectorizers_for_mf.ipynb**
  - loads the bag of words, dictionary for faster processing
- **Step4_train_models_gensim_for_mf.ipynb**
  - trains model on data to get topic_dist and mf data scores
- **Step5_multilevel_testing.ipynb**
  - does multi level processing
